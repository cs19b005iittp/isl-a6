# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p6zbA4LnEALqQJiENkGDDYtKfGstvRyn
"""

import torch
from torch import nn

def kali():
  print ('kali')

class cs19b005NN(nn.Module):

    def __init__(self, config):  
        super().__init__()
        self.conv = []
        self.relu = []
        self.maxpool = []
        self.layers = 0
        self.output_size = 0
        for in_channels, out_channels, kernel_size, stride in config:
            self.conv.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, stride=stride, padding=padding))
            self.relu.append(nn.ReLU())
            self.maxpool.append(nn.MaxPool2d(kernel_size=kernel_size, stride=stride))
            self.output_size = out_channels
            self.layers+=1
        # self.conv1 = nn.Conv2d(in_channels=input_size, out_channels=20, kernel_size=kernel_size, stride=stride, padding=padding)
        # self.relu1 = nn.ReLU()
        # self.maxpool1 = nn.MaxPool2d(kernel_size=kernel_size, stride=stride)

        # self.conv2d = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=kernel_size, stride=stride, padding=padding)
        # self.relu2 = nn.ReLU()
        # self.maxpool2 = nn.MaxPool2d(kernel_size=kernel_size, stride=stride)

        self.fc1 = nn.Linear(in_features=800, out_features=500)
        self.relu3 = nn.ReLU()

        self.fc2 = nn.Linear(in_features=500, out_features=output_size)
        self.logSoftmax = nn.LogSoftmax(dim=1)
    
    def forward(self, x):

        for i in range(self.layers):
            x = self.conv[i](x)
            x = self.relu[i](x)
            x = self.maxpool[i](x)

        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = self.relu3(x)

        x = self.fc2(x)

        output = self.logSoftmax(x)
        return output

def get_model(train_data_loader=None, n_epochs=10):
    model = cs19b005NN([(28*28, 10, (2,2), 'same')])
    print ('Returning model... (rollnumber: xx)')

    return model

device = "cuda" if torch.cuda.is_available() else "cpu"

loss_fn = nn.CrossEntropyLoss()

accuracy_val, precision_val, recall_val, f1score_val = 0, 0, 0, 0

def get_model_advanced(train_data_loader=None, n_epochs=10,lr=1e-4,config=None):
    model = cs19b005NN(config)
    # batch_size = 64

    for e in range(n_epochs):
        model.train()
        totalTrainLoss = 0
        trainCorrect = 0
        for (x, y) in train_data_loader:
            (x, y) = (x.to(device), y.to(device))
            pred = model(x)
            loss = loss_fn(pred, y)
            optimizer = torch.optim.SGD(model.parameters(), lr = lr)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            totalTrainLoss += loss
            trainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()
    
    print('returning model...')
    print(totalTrainLoss, trainCorrect)
    return model

def test_model(model1=None, test_data_loader=None):

    accuracy_val, precision_val, recall_val, f1score_val = 0, 0, 0, 0
    total_loss, val_correct= 0, 0
    with torch.no_grad():
        model1.eval()
        for x,y in test_data_loader:
            x, y = x.to(device), y.to(device)
            pred = model1(x)
            total_loss+=loss_fn(pred,y)
            val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()
        len_data = len(test_data_loader.dataset)
        accuracy_val = val_correct/len_data
        
    print ('Returning metrics... (rollnumber: xx)')
    return accuracy_val, precision_val, recall_val, f1score_val